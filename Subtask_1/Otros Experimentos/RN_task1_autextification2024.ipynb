{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "07hE55JzNEcd"
      },
      "outputs": [],
      "source": [
        "#Importamos los paquetes necesarios para el funcionamiento.\n",
        "import csv\n",
        "import tensorflow\n",
        "tensorflow.config.run_functions_eagerly(False)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tqdm import tqdm\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usaremos colab para cargar los documentos de la tarea 1.\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "ycEj10ABxjDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Método add_feature1\n",
        "Toma una matriz dispera x y agrega una o más características adicionales.\n",
        "@param: dos matrices en formato csv.\n",
        "@return: una matriz en formato csr.\n",
        "\"\"\"\n",
        "def add_feature1(X, feature_to_add):\n",
        "    from scipy.sparse import csr_matrix, hstack\n",
        "    # Se concatena la secuncia de caracteres del conjunto de train con un matriz dispersa\n",
        "    return hstack([X, csr_matrix(feature_to_add)], 'csr')\n",
        "\n",
        "\"\"\"\n",
        "Método plot_graphs\n",
        "Genera gráficos qeu muestra la evolución de métricas como pérdida o precisió, tanto en los datos de entrenamiento como de validación.\n",
        "@param: history -> la historia del modelo, string -> el nombre de la métrica a graficar.\n",
        "@return: Gráfico\n",
        "\"\"\"\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "y0kUXNrWNP9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Obetenemos los datos de entrenamiento y validación ya refinados.\n",
        "\"\"\"\n",
        "#Dataset roberta finetuned\n",
        "train_roberta = pd.read_csv('/content/gdrive/MyDrive/subtask_1/train_subtask1xlm-roberta-base-finetuned-IberAuTexTification2024-7030-4epo-task1-v2.csv', header=None)\n",
        "test_roberta = pd.read_csv('/content/gdrive/MyDrive/subtask_1/test_subtask1xlm-roberta-base-finetuned-IberAuTexTification2024-7030-4epo-task1-v2.csv', header=None)\n",
        "\n",
        "#Dataset bert\n",
        "train_bert = pd.read_csv('/content/gdrive/MyDrive/subtask_1/train_subtask1bert-base-multilingual-cased-finetuned-autext24.csv', header=None)\n",
        "test_bert = pd.read_csv('/content/gdrive/MyDrive/subtask_1/test_subtask1bert-base-multilingual-cased-finetuned-autext24.csv', header=None)\n",
        "\n",
        "#Dataset e5\n",
        "train_e5 = pd.read_csv('/content/gdrive/MyDrive/subtask_1/train_subtask1multilingual-e5-large-finetuned-autext24.csv', header=None)\n",
        "test_e5 = pd.read_csv('/content/gdrive/MyDrive/subtask_1/test_subtask1multilingual-e5-large-finetuned-autext24.csv', header=None)\n",
        "\n",
        "#Dataset stylometry\n",
        "train_stylometry = pd.read_csv('/content/gdrive/MyDrive/subtask_1/stylometry_train_S1.csv')\n",
        "test_stylometry = pd.read_csv('/content/gdrive/MyDrive/subtask_1/stylometry_test_S1.csv')\n"
      ],
      "metadata": {
        "id": "jql5y8AEqEkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset original\n",
        "train_data = pd.read_csv('/content/gdrive/MyDrive/subtask_1/train_S1.csv')\n",
        "test_data = pd.read_csv('/content/gdrive/MyDrive/subtask_1/test_S1.csv')\n",
        "\n",
        "#Convertimos la columna \"label\" en etiquetas binarias, si el valor es \"generated\", le dará el valor de 1 o de lo contrario será 0.\n",
        "train_data['label'] = np.where(train_data['label']=='generated',1,0)\n",
        "test_data['label'] = np.where(test_data['label']=='generated',1,0)\n",
        "\n",
        "#A la columna text del conjunto se le asignan las características independientes, mientras que a la columna \"label\" la etiqueta.\n",
        "X_train_data = train_data['text']\n",
        "y_train_data = train_data['label']\n",
        "\n",
        "#A la columna text del conjunto se le asignan las características independientes, mientras que a la columna \"label\" la etiqueta.\n",
        "X_test_data = test_data['text']\n",
        "y_test_data = test_data['label']\n",
        "\n",
        "#Mostramos las dimensiones (número de filas y columnas) de los datos de entrenamiento y de validación.\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "id": "k1yhJi5K1Q8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Datos de entrenamiento\n",
        "#Unimos todas las características para el entrenamiento en un solo objeto.\n",
        "X_train_data = add_feature1(train_stylometry, train_bert)\n",
        "X_train_data = add_feature1(X_train, train_e5)\n",
        "X_train_data = add_feature1(X_train, train_roberta)\n",
        "\n",
        "#Datos de prueba\n",
        "#Unimos todas las características oara la validación en un solo objeto.\n",
        "X_test_data = add_feature1(test_roberta, test_bert)\n",
        "X_test_data = add_feature1(X_test, test_e5)\n",
        "X_test_data = add_feature1(X_test, test_stylometry)"
      ],
      "metadata": {
        "id": "Ip_uBMTjqHck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Volvemos a mostrar las dimensiones de las características viendo que coincidan en el número de filas\n",
        "print(X_train_data.shape)\n",
        "print(y_train_data.shape)"
      ],
      "metadata": {
        "id": "MBx-G59jpbLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Comenzamos el procseo de la Red Neuronal simple.\n",
        "Con la primera capa densa conectada con 128 neuronas y la segundo con 64 con la función ReLu que introduce la no linealiedad, además que X_train_data.shape[1] defina las entradas en la red.\n",
        "El primer y segundo dropout que desactiva el 20% de las neuronas para prevenir el sobreajuste.\n",
        "Finalmente con una capa de salida con la función sigmoid debido a que estamos haciendo una clasificación binaria.\n",
        "Si fuera el task 2, se usariía softmax para esta última capa ya que son más de dos categorías de salida.\n",
        "\"\"\"\n",
        "model = tensorflow.keras.Sequential([\n",
        "    tensorflow.keras.layers.Dense(128, activation='relu', input_shape = (X_train_data.shape[1],)),\n",
        "    tensorflow.keras.layers.Dropout(0.2),\n",
        "    tensorflow.keras.layers.Dense(64, activation='relu'),\n",
        "    tensorflow.keras.layers.Dropout(0.2),\n",
        "    tensorflow.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\"\"\"\n",
        "Creamos el optimizador Adam con un learning rate de 0.001 que es lo que controla el tamali de los pasos que toma durante la actualización.\n",
        "\"\"\"\n",
        "learning_rate = 0.001\n",
        "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\"\"\"\n",
        "Compilamos el modelo con la función de pérdida binary_crossentropy, el optimizador Adam y la métrica de precisión, que mide el rendimiento del modelo.\n",
        "\"\"\"\n",
        "model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "model.summary() #Mostramos el modelo"
      ],
      "metadata": {
        "id": "rWcKlWxPqRGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Se entrena el modelo con los datos proporcionados, donde history almacena el historial del entrenamiento.\n",
        "@X_train_data: Datos de entrada.\n",
        "@y_train_data: Datos de salida correpondientes a X_train_data.\n",
        "@epochs: El número de veces que el modelo pasrá por el conjunto, entre más mejor.\n",
        "@batch_size: Define el tamaño en el que los datos se dividirán para el entrenamiento.\n",
        "@validation_split: Define la fracción de los datos de entrenamiento que se utilizarán para la validación.\n",
        "\"\"\"\n",
        "history = model.fit(X_train_data, y_train_data, epochs=5, batch_size=128, validation_split=0.3)"
      ],
      "metadata": {
        "id": "yP0iyhsQqUKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Usamos el método anteriormente creado.\n",
        "Donde accurcay represneta la precisión de los datos de entrenamiento.\n",
        "Y val_accuracy representa la precisión de los datos de validación.\n",
        "\"\"\"\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5njA2NWZqUMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluación, checamos para saber la precisión del modelo que se medirá en una probabbilidad de 0 a 1.\n",
        "test_loss,test_acc = model.evaluate(X_test, y_test_data)\n",
        "print('Test Accuracy: ', test_acc)"
      ],
      "metadata": {
        "id": "-M7_vhSiqUOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}